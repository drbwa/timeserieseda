{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitpy37scipycondaea1ea709319942a2b87cdaaf37e04589",
   "display_name": "Python 3.7.6 64-bit ('py37scipy': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Machine Learning Models\n",
    "\n",
    "Continuation of notes about SciPy2019 talk by Aileen Nielsen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Time series feature generation\n",
    "\n",
    "There are no (none at all?) machine learning algorithms that have been specifically developed for handling time series models. Indeed, many ml algorithms do not support the notion of temporal data. Therefore, it is necessary to make your time series data fit into a representation that the ml algorithm in question does support. For example, Decision Trees are not built to handle temporal data.\n",
    "\n",
    "You can handle this mismatch by generating suitable features from your time series data. For example, record the minimum and maximum values (and time stamps?), count the number of peaks and valleys in time windows, compute the mean and median over such windows.\n",
    "\n",
    "If you have many time series that span long periods of time and compute such features once every minute (or whatever the time step in your data is), then this can become computationally expensive.\n",
    "\n",
    "There are canonical feature sets that have been developed for time series. According to Aileen, if you have a specific use case / domain, you should be able to do better than a canonical feature set using domain knowledge and analyzing your data. Time series features are discipline-specific. \n",
    "\n",
    "This may be true, but still wondering what to do when faced with very large multivariate time series datas sets. \n",
    "\n",
    "A few of the models being discussed:\n",
    "* Random Forests using xgboost. You learn your first decision tree and then learn the second one based on the errors of the first one. In practice, xgboost is said to perform well with time series classification.\n",
    "* Clustering. Difficult both conceptually and due to computational costs. Need to be careful to pick a good distance metric (e.g., not Euclidean distance). Need to be careful that you really cluster time series with similar features. Put differently, you need to find features that distinguish well between different time series (domain knowledge?).\n",
    "  * Clustering can be based on features that you identify in time series (e.g., either by looking for the features from a canonical set or with custom-code to look for relevant features in your domain). This can become computationally expensive. Think thousands of time series each with tens of thousands of data points you need to analyze.\n",
    "  * Clustering can also be done using a suitable distance metric. The one recommended for time series data is [Dynamic Time Warping](https://en.wikipedia.org/wiki/Dynamic_time_warping).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Classification using trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'reraise' from 'dask.compatibility' (/Users/brunow/anaconda3/envs/py37scipy/lib/python3.7/site-packages/dask/compatibility.py)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-db3091aa60d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcesium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcesium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeaturize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37scipy/lib/python3.7/site-packages/cesium/featurize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreaded\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpack_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'reraise' from 'dask.compatibility' (/Users/brunow/anaconda3/envs/py37scipy/lib/python3.7/site-packages/dask/compatibility.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cesium\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from cesium import datasets\n",
    "from cesium import featurize as ft\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.stats import skew\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 10]"
   ]
  },
  {
   "source": [
    "There are packages that can extract features from time series. `cesium` is one such package. More [details](https://github.com/cesium-ml/cesium), including the list of features, such as number of peaks, index of $i^{th}$ largest peak, total number of observed values, difference between maximum and minimum time values, mean of time values, amplitude, skewness and many more."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}